import streamlit as st
import os
import sys
from pathlib import Path
# LangChain imports
from langchain.prompts.chat import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# Import our custom DeepSeek LLM
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from deepseek_llm import DeepSeekLLM

st.markdown("<h1 style='text-align: center;'>ğŸ˜°é£é™©è¯„ä¼°</h1>", unsafe_allow_html=True)


def init_deepseek_chain():
    """Initialize DeepSeek LLM with LangChain chain"""
    # å°è¯•å¤šç§æ–¹å¼è·å–APIå¯†é’¥
    api_key = os.getenv("DEEPSEEK_API_KEY")
    
    # å¦‚æœç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰é…ç½®æ–‡ä»¶
    if not api_key:
        config_file = Path(__file__).parent.parent / "config.json"
        if config_file.exists():
            try:
                import json
                with open(config_file, 'r',encoding='utf-8') as f:
                    config = json.load(f)
                    api_key = config.get("deepseek_api_key")
            except Exception as e:
                st.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
                return None
    
    try:
        # Create DeepSeek LLM instance
        llm = DeepSeekLLM(
            model="deepseek-chat",
            api_key=api_key,
            temperature=0.7,
            max_tokens=1024
        )
        
        # ç®€å•çš„APIè¿æ¥æµ‹è¯•ï¼ˆä¸æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯ï¼‰
        test_response = llm._call("Hi", max_tokens=5)
        
    except Exception as e:
        st.error(f"âŒ DeepSeek API åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return None
######################################################################
    # Create prompt template using ChatPromptTemplate
    system_template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°é£æ°”è±¡æ•°æ®åˆ†æä¸“å®¶ã€‚è¯·åŸºäºæä¾›çš„å†å²å°é£æ•°æ®è¿›è¡Œé£é™©è¯„ä¼°åˆ†æã€‚
    
æ•°æ®è¯´æ˜ï¼š
- æ•°æ®ä¸€ï¼šå†å¹´å„å­£èŠ‚çš„å°é£æ•°é‡ç»Ÿè®¡
- æ•°æ®äºŒï¼šå„å¹´ç™»é™†å°é£çš„åœ°ç†ä½ç½®åæ ‡å’Œç»çº¬åº¦ä¿¡æ¯

åˆ†æè¦æ±‚ï¼š
1. å°é£é¢‘ç‡éšå¹´ä»½çš„å˜åŒ–è¶‹åŠ¿
2. ä¸åŒå¼ºåº¦å°é£çš„åˆ†å¸ƒç‰¹æ€§ï¼ˆå¦‚è·¯å¾„é›†ä¸­åŒºåŸŸã€ç™»é™†åœ°ç‚¹ç»Ÿè®¡ï¼‰
3. ä¸åŒæ—¶é—´æ®µï¼ˆå¦‚å¤å­£ vs å†¬å­£ï¼‰çš„å°é£æ´»åŠ¨å¯¹æ¯”
4. åŸºäºå†å²æ•°æ®çš„é£é™©è¯„ä¼°

è¯·ç¡®ä¿å›ç­”ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡20è¡Œã€‚"""

    human_template = """{user_query}

æ•°æ®ä¸€ï¼ˆå†å¹´å„å­£èŠ‚å°é£æ•°é‡ï¼‰ï¼š
{seasonal_data}

æ•°æ®äºŒï¼ˆç™»é™†å°é£ä½ç½®ä¿¡æ¯ï¼‰ï¼š
{landing_data}"""
#######################################################################
    
    # prompt
    chat_prompt = ChatPromptTemplate.from_messages([
        ("system", system_template),
        ("human", human_template)
    ])
    
    # Create output parser
    output_parser = StrOutputParser()
    
    # the chain
    chain = chat_prompt | llm | output_parser
    return chain


def load_typhoon_data():
    """Load typhoon data files"""
    try:
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ï¼ˆdesignç›®å½•ï¼‰
        script_dir = Path(__file__).parent.parent
        
        # Load seasonal typhoon data
        seasonal_file = script_dir / "result" / "llmdata" / "year_season_typhoon.csv"
        if not seasonal_file.exists():
            st.error(f"å­£èŠ‚æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {seasonal_file}")
            return None, None
            
        with open(seasonal_file, 'r', encoding='utf-8') as f:
            seasonal_data = f.read()
        
        # Load landing data
        landing_file = script_dir / "result" / "llmdata" / "year_landings_addr.csv"
        if not landing_file.exists():
            st.error(f"ç™»é™†æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {landing_file}")
            return None, None
            
        with open(landing_file, 'r', encoding='utf-8') as f:
            landing_data = f.read()
            
        return seasonal_data, landing_data
    except Exception as e:
        st.error(f"æ•°æ®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return None, None


# User interface
user_input = st.text_input(
    label='è¯·è¾“å…¥æ‚¨çš„åˆ†æéœ€æ±‚:',
    value="ç”Ÿæˆå°é£åˆ†ææŠ¥å‘Š",
    help="ä¾‹å¦‚ï¼šç”Ÿæˆå°é£é£é™©è¯„ä¼°æŠ¥å‘Šã€åˆ†æå°é£ç™»é™†è¶‹åŠ¿ç­‰"
)

if st.button('ç”Ÿæˆé£é™©è¯„ä¼°æŠ¥å‘Š'):
    # åªåœ¨ç‚¹å‡»æŒ‰é’®æ—¶åˆå§‹åŒ–å¹¶æ£€æŸ¥API
    with st.spinner('åˆå§‹åŒ– DeepSeek LLM...'):
        chain = init_deepseek_chain()
    
    if chain is None:
        st.error("LLM åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API é…ç½®")
    else:
        # Load data
        seasonal_data, landing_data = load_typhoon_data()
        
        if seasonal_data and landing_data:
            try:
                with st.spinner('æ­£åœ¨ç”Ÿæˆé£é™©è¯„ä¼°æŠ¥å‘Š...'):
                    # Use the LangChain chain to generate response
                    response = chain.invoke({
                        "user_query": user_input,
                        "seasonal_data": seasonal_data,
                        "landing_data": landing_data
                    })
                    
                    # Display the result
                    st.subheader("ğŸŒªï¸ å°é£é£é™©è¯„ä¼°æŠ¥å‘Š")
                    st.markdown(response)
                    
            except Exception as e:
                st.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")
        else:
            st.error("æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨")



# Add configuration section in sidebar
st.sidebar.header("âš™ï¸ é…ç½®")
st.sidebar.markdown("""
**å½“å‰é…ç½®:**
- æ¨¡å‹: DeepSeek Chat
- æ¡†æ¶: LangChain
- æ¸©åº¦: 0.7
- æœ€å¤§ä»¤ç‰Œ: 1024

**æ•°æ®æº:**
- å†å¹´å­£èŠ‚å°é£ç»Ÿè®¡
- ç™»é™†å°é£ä½ç½®æ•°æ®
""")

if st.sidebar.button("æ£€æŸ¥æ•°æ®æ–‡ä»¶"):
    script_dir = Path(__file__).parent.parent
    seasonal_file = script_dir / "result" / "llmdata" / "year_season_typhoon.csv"
    landing_file = script_dir / "result" / "llmdata" / "year_landings_addr.csv"
    
    st.sidebar.write("æ–‡ä»¶çŠ¶æ€:")
    st.sidebar.write(f"- å­£èŠ‚ç»Ÿè®¡æ–‡ä»¶: {'âœ… å­˜åœ¨' if seasonal_file.exists() else 'âŒ ç¼ºå¤±'}")
    st.sidebar.write(f"- ç™»é™†æ•°æ®æ–‡ä»¶: {'âœ… å­˜åœ¨' if landing_file.exists() else 'âŒ ç¼ºå¤±'}")
    
    if not seasonal_file.exists():
        st.sidebar.write(f"  è·¯å¾„: {seasonal_file}")
    if not landing_file.exists():
        st.sidebar.write(f"  è·¯å¾„: {landing_file}")