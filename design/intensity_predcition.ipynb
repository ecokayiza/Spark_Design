{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,count,mean,udf,sum,when\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Typhoon Analyze\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "spark.conf.set(\"spark.rapids.sql.enable\",\"true\")\n",
    "\n",
    "\n",
    "df_grade=spark.read.option(\"header\", True).csv(r\"../design/result/grade_trend/part-00000-7dcf4de8-72b3-42bb-bf65-4d2d581f866e-c000.csv\")\n",
    "df_intensity=spark.read.option(\"header\", True).csv(r\"../design/result/intensity_trend/part-00000-230f148b-8c77-4f42-bc0c-4d0236d48799-c000.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------------+\n",
      "|year|avg_central_pressure|    avg_wind_speed|\n",
      "+----+--------------------+------------------+\n",
      "|1977|   986.1454311454312|31.975546975546976|\n",
      "|1978|   986.0371747211896| 34.02416356877323|\n",
      "|1979|   983.2565997888067| 35.45406546990496|\n",
      "|1980|    984.497641509434|  36.6627358490566|\n",
      "|1981|   985.9777777777778|  30.7979797979798|\n",
      "|1982|   981.8138195777351|41.602687140115165|\n",
      "|1983|   985.1509433962265|34.782293178519595|\n",
      "|1984|   985.1949339207049|35.401982378854626|\n",
      "|1985|   989.1456815816857| 32.43496357960458|\n",
      "|1986|   985.3704891740176| 34.86367281475541|\n",
      "|1987|   978.7153679653679| 43.52272727272727|\n",
      "|1988|     988.74715261959|  32.2380410022779|\n",
      "|1989|   983.5480116391852| 37.59456838021339|\n",
      "|1990|   981.2694198623402| 40.08849557522124|\n",
      "|1991|   978.0804416403786| 43.71845425867508|\n",
      "|1992|   981.2928679817906| 39.55993930197268|\n",
      "|1993|   987.3385321100917| 33.41284403669725|\n",
      "|1994|   983.7460857726345| 38.35602450646699|\n",
      "|1995|   987.7876712328767| 33.50684931506849|\n",
      "|1996|   983.5871886120997|36.837188612099645|\n",
      "+----+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "df_intensity = df_intensity.withColumn(\"year\", df_intensity[\"year\"].cast(IntegerType()))\n",
    "df_intensity = df_intensity.withColumn(\"avg_central_pressure\", df_intensity[\"avg_central_pressure\"].cast(\"double\"))\n",
    "df_intensity = df_intensity.withColumn(\"avg_wind_speed\", df_intensity[\"avg_wind_speed\"].cast(\"double\"))\n",
    "df_intensity = df_intensity.filter(df_intensity.year >= 1977)\n",
    "df_intensity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|year|    avg_wind_speed|\n",
      "+----+------------------+\n",
      "|1977|31.975546975546976|\n",
      "|1978| 34.02416356877323|\n",
      "|1979| 35.45406546990496|\n",
      "|1980|  36.6627358490566|\n",
      "|1981|  30.7979797979798|\n",
      "|1982|41.602687140115165|\n",
      "|1983|34.782293178519595|\n",
      "|1984|35.401982378854626|\n",
      "|1985| 32.43496357960458|\n",
      "|1986| 34.86367281475541|\n",
      "+----+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_intensiy_wind = df_intensity.filter(df_intensity.avg_wind_speed.isNotNull()).drop('avg_central_pressure')\n",
    "df_intensiy_wind.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|year|avg_central_pressure|\n",
      "+----+--------------------+\n",
      "|1977|   986.1454311454312|\n",
      "|1978|   986.0371747211896|\n",
      "|1979|   983.2565997888067|\n",
      "|1980|    984.497641509434|\n",
      "|1981|   985.9777777777778|\n",
      "|1982|   981.8138195777351|\n",
      "|1983|   985.1509433962265|\n",
      "|1984|   985.1949339207049|\n",
      "|1985|   989.1456815816857|\n",
      "|1986|   985.3704891740176|\n",
      "+----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[year: int, avg_central_pressure: double]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intensity_pressure = df_intensity.drop('avg_wind_speed')\n",
    "df_intensity_pressure.show(10)\n",
    "df_intensity_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for central pressure prediction: 3.473577220150774\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "#预测强度的回归模型\n",
    "# year作为输入，输出强度\n",
    "# 提取特征向量\n",
    "assembler = VectorAssembler(inputCols=[\"year\"], outputCol=\"features\")\n",
    "df_intensity_features = assembler.transform(df_intensity_pressure)\n",
    "\n",
    "#划分训练集和测试集\n",
    "pressure_train, pressure_test = df_intensity_features.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "#训练\n",
    "pressure_model = LinearRegression(featuresCol=\"features\", labelCol=\"avg_central_pressure\", regParam=0.1)\n",
    "lr_model_central_pressure = pressure_model.fit(pressure_train)\n",
    "\n",
    "#预测\n",
    "pressure_prediction = lr_model_central_pressure.transform(pressure_test)\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"avg_central_pressure\", metricName=\"rmse\")\n",
    "rmse_central_pressure = evaluator.evaluate(pressure_prediction)\n",
    "\n",
    "print(f\"RMSE for central pressure prediction: {rmse_central_pressure}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----------------+\n",
      "|year|features|       prediction|\n",
      "+----+--------+-----------------+\n",
      "|2015|[2015.0]|983.6482701040463|\n",
      "|2016|[2016.0]|983.6388986396908|\n",
      "|2017|[2017.0]|983.6295271753352|\n",
      "|2018|[2018.0]|983.6201557109796|\n",
      "|2019|[2019.0]| 983.610784246624|\n",
      "|2020|[2020.0]|983.6014127822684|\n",
      "|2021|[2021.0]| 983.592041317913|\n",
      "|2022|[2022.0]|983.5826698535574|\n",
      "|2023|[2023.0]|983.5732983892018|\n",
      "|2024|[2024.0]|983.5639269248462|\n",
      "|2025|[2025.0]|983.5545554604906|\n",
      "|2026|[2026.0]| 983.545183996135|\n",
      "|2027|[2027.0]|983.5358125317795|\n",
      "|2028|[2028.0]|983.5264410674239|\n",
      "|2029|[2029.0]|983.5170696030683|\n",
      "|2030|[2030.0]|983.5076981387128|\n",
      "|2031|[2031.0]|983.4983266743573|\n",
      "|2032|[2032.0]|983.4889552100017|\n",
      "+----+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "future_years = spark.createDataFrame([(year,) for year in range(2015, 2033)], [\"year\"])\n",
    "future_years_features = assembler.transform(future_years)\n",
    "pressure_predictions = lr_model_central_pressure.transform(future_years_features)\n",
    "pressure_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for wind speed prediction: 3.987021392568346\n"
     ]
    }
   ],
   "source": [
    "# 提取特征向量\n",
    "assembler_wind = VectorAssembler(inputCols=[\"year\"], outputCol=\"features\")\n",
    "df_intensiy_wind_features = assembler_wind.transform(df_intensiy_wind)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "wind_train, wind_test = df_intensiy_wind_features.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# 训练\n",
    "wind_model = LinearRegression(featuresCol=\"features\", labelCol=\"avg_wind_speed\",regParam=0.1)\n",
    "lr_model_wind_speed = wind_model.fit(wind_train)\n",
    "\n",
    "# 预测\n",
    "wind_prediction = lr_model_wind_speed.transform(wind_test)\n",
    "\n",
    "evaluator_wind = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"avg_wind_speed\", metricName=\"rmse\")\n",
    "rmse_wind_speed = evaluator_wind.evaluate(wind_prediction)\n",
    "\n",
    "print(f\"RMSE for wind speed prediction: {rmse_wind_speed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------------------+\n",
      "|year|features|        prediction|\n",
      "+----+--------+------------------+\n",
      "|2015|[2015.0]|  37.5224634705423|\n",
      "|2016|[2016.0]|  37.5457055616171|\n",
      "|2017|[2017.0]|  37.5689476526919|\n",
      "|2018|[2018.0]| 37.59218974376669|\n",
      "|2019|[2019.0]| 37.61543183484149|\n",
      "|2020|[2020.0]| 37.63867392591629|\n",
      "|2021|[2021.0]| 37.66191601699108|\n",
      "|2022|[2022.0]| 37.68515810806588|\n",
      "|2023|[2023.0]| 37.70840019914068|\n",
      "|2024|[2024.0]| 37.73164229021547|\n",
      "|2025|[2025.0]| 37.75488438129027|\n",
      "|2026|[2026.0]| 37.77812647236507|\n",
      "|2027|[2027.0]|37.801368563439866|\n",
      "|2028|[2028.0]| 37.82461065451466|\n",
      "|2029|[2029.0]|37.847852745589456|\n",
      "|2030|[2030.0]|37.871094836664255|\n",
      "|2031|[2031.0]| 37.89433692773905|\n",
      "|2032|[2032.0]|37.917579018813846|\n",
      "+----+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "future_years = spark.createDataFrame([(year,) for year in range(2015, 2033)], [\"year\"])\n",
    "future_years_features = assembler_wind.transform(future_years)\n",
    "wind_predictions = lr_model_wind_speed.transform(future_years_features)\n",
    "wind_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 361:==============>(63 + 1) / 64][Stage 362:======>       (30 + 34) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+--------------------+\n",
      "|year|predicted_pressure|predicted_wind_speed|\n",
      "+----+------------------+--------------------+\n",
      "|2015| 983.6482701040463|    37.5224634705423|\n",
      "|2016| 983.6388986396908|    37.5457055616171|\n",
      "|2017| 983.6295271753352|    37.5689476526919|\n",
      "|2018| 983.6201557109796|   37.59218974376669|\n",
      "|2019|  983.610784246624|   37.61543183484149|\n",
      "|2020| 983.6014127822684|   37.63867392591629|\n",
      "|2021|  983.592041317913|   37.66191601699108|\n",
      "|2022| 983.5826698535574|   37.68515810806588|\n",
      "|2023| 983.5732983892018|   37.70840019914068|\n",
      "|2024| 983.5639269248462|   37.73164229021547|\n",
      "|2025| 983.5545554604906|   37.75488438129027|\n",
      "|2026|  983.545183996135|   37.77812647236507|\n",
      "|2027| 983.5358125317795|  37.801368563439866|\n",
      "|2028| 983.5264410674239|   37.82461065451466|\n",
      "|2029| 983.5170696030683|  37.847852745589456|\n",
      "|2030| 983.5076981387128|  37.871094836664255|\n",
      "|2031| 983.4983266743573|   37.89433692773905|\n",
      "|2032| 983.4889552100017|  37.917579018813846|\n",
      "+----+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 合并两个预测结果\n",
    "combined_predictions = pressure_predictions.select(\"year\", \"prediction\").withColumnRenamed(\"prediction\", \"predicted_pressure\") \\\n",
    "    .join(wind_predictions.select(\"year\", \"prediction\").withColumnRenamed(\"prediction\", \"predicted_wind_speed\"), on=\"year\", how=\"inner\")\n",
    "\n",
    "combined_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "combined_predictions.coalesce(1).write.mode(\"overwrite\").option(\"header\",True).csv(\"result/intensity_prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
